# Agent PR Loop â€” design -> todo -> implement -> (review <-> fix)* -> (optional) PR
#
# Readability goals:
# - LLM steps use `worker: OPENCODE | CLAUDE_CODE` directly.
# - Small orchestration lives in scripts.
#
# Run on another workspace (any git repo directory):
#   ROBOPPI_ROOT=/path/to/roboppi
#   TARGET=/path/to/your/repo
#   ROBOPPI_ROOT="$ROBOPPI_ROOT" bun run --cwd "$ROBOPPI_ROOT" ./src/workflow/run.ts \
#     "$ROBOPPI_ROOT/examples/agent-pr-loop.yaml" --workspace "$TARGET" --verbose

name: agent-pr-loop
version: "1"
description: "Design+Todo by OpenCode, implement by Claude Code (looped), review gate by OpenCode, then (optionally) create a PR."
# Budget note: full path with max review iterations can exceed 90m.
timeout: "300m"
concurrency: 1
create_branch: true
branch_transition_step: "branch"

steps:
  bootstrap:
    description: "Validate inputs/tools and initialize loop state"
    worker: CUSTOM
    instructions: |
      bash "${ROBOPPI_ROOT:-${AGENTCORE_ROOT:-.}}/scripts/agent-pr-loop/bootstrap.sh"
    capabilities: [READ, EDIT, RUN_COMMANDS]
    timeout: "2m"

  branch:
    description: "Create or reuse a working branch"
    worker: CUSTOM
    depends_on: [bootstrap]
    instructions: |
      bash "${ROBOPPI_ROOT:-${AGENTCORE_ROOT:-.}}/scripts/agent-pr-loop/branch.sh"
    capabilities: [READ, RUN_COMMANDS]
    timeout: "1m"

  design:
    description: "Design (OpenCode / GPT-5.2)"
    worker: OPENCODE
    model: "openai/gpt-5.2"
    depends_on: [branch]
    instructions: |
      You are OpenCode.

      Task: Produce a design doc ONLY (no implementation).

      Read:
      - .roboppi-loop/request.md

      Write/update:
      - .roboppi-loop/design.md

      Design doc requirements:
      - Problem statement + goals/non-goals
      - Proposed approach + alternatives considered
      - Data model / interfaces (as needed)
      - Execution plan at high level
      - Risks/edge cases + observability/testing notes
      - Explicit acceptance criteria checklist
    capabilities: [READ, EDIT]
    timeout: "20m"
    on_failure: retry
    max_retries: 2
    outputs:
      - name: design
        path: ".roboppi-loop/design.md"
        type: review

  todo:
    description: "Turn design into an implementation TODO (OpenCode / GPT-5.2)"
    worker: OPENCODE
    model: "openai/gpt-5.2"
    depends_on: [design]
    instructions: |
      You are OpenCode.

      Task: Convert the design into a concrete TODO checklist.

      Read:
      - .roboppi-loop/request.md
      - .roboppi-loop/design.md

      Write/update:
      - .roboppi-loop/todo.md

      TODO requirements:
      - Use Markdown checklist items: "- [ ] ..."
      - Group tasks by milestones (small batches)
      - Include file paths when possible
      - Include at least 1 testing task (how to run + expected outcome)
      - Include at least 1 validation step (manual or automated)
      - Include rollback/escape hatch notes if risky

      If .roboppi-loop/todo.md already exists, improve it to satisfy the requirements.
    capabilities: [READ, EDIT]
    timeout: "20m"
    on_failure: retry
    max_retries: 2

    completion_check:
      worker: CUSTOM
      instructions: |
        bash "${ROBOPPI_ROOT:-${AGENTCORE_ROOT:-.}}/scripts/agent-pr-loop/todo-check.sh"
      capabilities: [READ, RUN_COMMANDS]
      timeout: "30s"

    max_iterations: 3
    on_iterations_exhausted: abort
    outputs:
      - name: todo
        path: ".roboppi-loop/todo.md"
        type: code

  implement:
    description: "Implement by Claude Code; review by OpenCode; repeat until PASS"
    worker: CLAUDE_CODE
    model: "claude-opus-4-6"
    depends_on: [todo]
    instructions: |
      You are Claude Code.

      Use Claude's team feature if available (split into implement/test/review roles internally).

      Read:
      - .roboppi-loop/request.md
      - .roboppi-loop/design.md
      - .roboppi-loop/todo.md
      - .roboppi-loop/review.md (if present)
      - .roboppi-loop/fix.md (if present)

      Task:
      - If .roboppi-loop/fix.md exists and is non-empty, apply ONLY those fixes (minimal, targeted changes).
      - Otherwise, implement the TODO checklist.
      - Update the TODO checkboxes as you complete items.
      - Run the repo's tests (or the best available test command) and fix failures.
      - Keep changes focused on the request.

      At the end, briefly report what was implemented and how to verify.
    capabilities: [READ, EDIT, RUN_TESTS, RUN_COMMANDS]
    timeout: "45m"
    on_failure: retry
    max_retries: 1

    # Convergence Controller (opt-in): detect stalled, repeating failures and
    # switch to a minimal-change mode before fail-fast with diagnosis.
    convergence:
      enabled: true
      stall_threshold: 2
      max_stage: 3
      fail_on_max_stage: true

    completion_check:
      worker: OPENCODE
      model: "openai/gpt-5.2"
      decision_file: ".roboppi-loop/review.verdict"
      instructions: |
        You are OpenCode.

        Task:
        - Review the work against the request.
        - Write/update:
          - .roboppi-loop/review.md
          - .roboppi-loop/review.verdict (structured JSON; see Output rules)
        - If verdict is FAIL, also write/update:
          - .roboppi-loop/fix.md (non-empty; concrete, actionable steps; include file paths)
        - If verdict is PASS:
          - Clear .roboppi-loop/fix.md if it exists (truncate to empty) so stale FAIL instructions cannot leak into future runs.

        Before reviewing, generate these review inputs (workspace is a git repo):
        - bash "${ROBOPPI_ROOT:-${AGENTCORE_ROOT:-.}}/scripts/agent-pr-loop/review-inputs.sh"

        You must read at least:
        - .roboppi-loop/request.md
        - .roboppi-loop/design.md (if present)
        - .roboppi-loop/todo.md (if present)
        - .roboppi-loop/review.base_ref
        - .roboppi-loop/review.diff
        - .roboppi-loop/review.status
        - .roboppi-loop/review.untracked
        - .roboppi-loop/review.untracked.diff

        Format for .roboppi-loop/review.md:
        - Sections: Summary, Strengths, Issues, Verification

        Output rules:
        - Write .roboppi-loop/review.verdict as a single-line JSON object:
          - PASS => {"decision":"complete","check_id":"$ROBOPPI_COMPLETION_CHECK_ID"}
          - FAIL => {"decision":"incomplete","check_id":"$ROBOPPI_COMPLETION_CHECK_ID"}
        - When FAIL, also include:
          - "reasons": ["..."]        (human-readable, short)
          - "fingerprints": ["..."]   (stable IDs; used by the Convergence Controller)
        - Fingerprint rules:
          - Stable across iterations for the *same* underlying issue.
          - Prefer file/line/test identifiers (e.g. "test:pkg/foo TestBar", "lint:src/x.ts:42", "scope:charts/...").
          - Keep each item short.
        - Fallback: if you cannot emit JSON, write legacy text "PASS" or "FAIL" only (no extra words).
        - If verdict is PASS, clear .roboppi-loop/fix.md if it exists (truncate to empty).
      capabilities: [READ, EDIT, RUN_COMMANDS]
      timeout: "15m"

    max_iterations: 5
    on_iterations_exhausted: abort
    outputs:
      - name: review
        path: ".roboppi-loop/review.md"
        type: review
      - name: verdict
        path: ".roboppi-loop/review.verdict"
        type: text
      - name: fix
        path: ".roboppi-loop/fix.md"
        type: code

  create_pr:
    description: "Create a PR (optional; requires .roboppi-loop/enable_pr)"
    worker: CUSTOM
    depends_on: [implement]
    instructions: |
      bash "${ROBOPPI_ROOT:-${AGENTCORE_ROOT:-.}}/scripts/agent-pr-loop/create-pr.sh"
    capabilities: [READ, EDIT, RUN_COMMANDS]
    timeout: "10m"
    outputs:
      - name: pr
        path: ".roboppi-loop/pr-url.txt"
        type: text
